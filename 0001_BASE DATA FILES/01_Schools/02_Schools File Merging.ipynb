{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4658ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8b7981",
   "metadata": {},
   "source": [
    "# 1. Africa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18272855",
   "metadata": {},
   "source": [
    "### Turning polygon schools into points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4286391c",
   "metadata": {},
   "source": [
    "Since some of the OSM schools are stored as polygons, we still need to turn them into points as well, so that they can seamlessly integrate with the point-based schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cfe44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original CRS: EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "## Loading the multipolygon GeoJSON\n",
    "multipolygon_file = \"Africa/schools_full_polygons.geojson\"\n",
    "gdf_multi = gpd.read_file(multipolygon_file)\n",
    "\n",
    "## Checking the current CRS\n",
    "print(f\"Original CRS: {gdf_multi.crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6889df88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting to projected CRS\n",
    "projected_gdf = gdf_multi.to_crs(\"EPSG:3857\")  \n",
    "\n",
    "## Computing the centroids in projected coordinates\n",
    "projected_gdf[\"geometry\"] = projected_gdf[\"geometry\"].centroid\n",
    "\n",
    "## Converting back to geographic CRS for saving\n",
    "gdf_multi = projected_gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "## Saving as GeoJSON\n",
    "centroid_geojson = \"Africa/schools_centroids.geojson\"\n",
    "gdf_multi.to_file(centroid_geojson, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97f4409",
   "metadata": {},
   "source": [
    "### Loading centroid and points file for cleaning and merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ff405ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## File paths\n",
    "nodes_file = \"Africa/schools_full_nodes.geojson\"\n",
    "centroids_file = \"Africa/schools_centroids.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c929707",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading both GeoJSON files\n",
    "with open(centroids_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    centroids_data = json.load(f)\n",
    "\n",
    "with open(nodes_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    nodes_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637844f0",
   "metadata": {},
   "source": [
    "### Expanding the other_tags column in the centroids file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7166a813",
   "metadata": {},
   "source": [
    "The centroids file, which are the centerpoints of the schools captured as polygons in OSM, has a large number of tags collapsed into a single column. In the nodes file, which contains the schools captured as points in OSM, these tags all receive a seperate column. This step makes this also the case for the centroids file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3dd5753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating function to extract tags\n",
    "\n",
    "def extract_other_tags(properties):\n",
    "    \"\"\"Extract key-value pairs from 'other_tags' and add them as separate columns.\"\"\"\n",
    "    if \"other_tags\" in properties and properties[\"other_tags\"]:\n",
    "        tag_str = properties[\"other_tags\"]\n",
    "        tag_dict = {}\n",
    "\n",
    "        #Extracting key-value pairs\n",
    "        matches = re.findall(r'\"(.*?)\"=>\"(.*?)\"', tag_str)\n",
    "        for key, value in matches:\n",
    "            tag_dict[key] = value\n",
    "\n",
    "        #Merging extracted tags into properties\n",
    "        properties.update(tag_dict)\n",
    "\n",
    "    #Removing the \"other_tags\" column since it's now expanded\n",
    "    properties.pop(\"other_tags\", None)\n",
    "    return properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18ef4111",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying extraction function\n",
    "for feature in centroids_data[\"features\"]:\n",
    "    feature[\"properties\"] = extract_other_tags(feature[\"properties\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbbc3cf",
   "metadata": {},
   "source": [
    "### Preparing centroid and node datasets for merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d1ea22",
   "metadata": {},
   "source": [
    "The two datasets have slightly different structures. Here, we are cleaning and processing them so that they can be merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce14b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating function to clean None values from properties\n",
    "def clean_properties(properties):\n",
    "    return {k: v for k, v in properties.items() if v is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f4dc51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing centroids: Removing None values & ensure \"name\" exists (if not, fallback to OSM ID)\n",
    "for feature in centroids_data[\"features\"]:\n",
    "    feature[\"properties\"] = clean_properties(feature[\"properties\"])\n",
    "\n",
    "    if \"name\" not in feature[\"properties\"] or not feature[\"properties\"][\"name\"]:\n",
    "        feature[\"properties\"][\"name\"] = f\"Unnamed School (OSM ID: {feature['properties'].get('osm_id', 'Unknown')})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79415390",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing nodes: Removing none values & ensure \"name\" exists (if not, fallback to OSM ID)\n",
    "for feature in nodes_data[\"features\"]:\n",
    "    feature[\"properties\"] = clean_properties(feature[\"properties\"])\n",
    "\n",
    "    if \"name\" not in feature[\"properties\"] or not feature[\"properties\"][\"name\"]:\n",
    "        feature[\"properties\"][\"name\"] = f\"Unnamed School (OSM ID: {feature['properties'].get('osm_id', 'Unknown')})\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952ab56d",
   "metadata": {},
   "source": [
    "### Merging the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf7c96df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging\n",
    "merged_features = centroids_data[\"features\"] + nodes_data[\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "244ee85d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172290"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the number of schools included:\n",
    "len(merged_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9df70a",
   "metadata": {},
   "source": [
    "### Checking columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4b088c",
   "metadata": {},
   "source": [
    "There is a strong variety in detail for each school: sometimes a lot of detail is provided, other times only the name. Here we are checking what the most commonly provided details are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07f7db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating function to count non-null values in each column\n",
    "def count_non_nulls(features):\n",
    "    column_counts = defaultdict(int)\n",
    "    total_features = len(features)\n",
    "\n",
    "    for feature in features:\n",
    "        for key, value in feature[\"properties\"].items():\n",
    "            if value not in [None, \"\"]: \n",
    "                column_counts[key] += 1\n",
    "\n",
    "    return dict(column_counts), total_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f00ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Counting non-null values\n",
    "counts, total = count_non_nulls(merged_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d6bab4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting counts to dataframe for easy sorting\n",
    "merged_df = pd.DataFrame(list(counts.items()), columns=[\"Column\", \"Non-Null Count\"])\n",
    "merged_df[\"Total Features\"] = total\n",
    "merged_df[\"Coverage (%)\"] = (merged_df[\"Non-Null Count\"] / total) * 100\n",
    "merged_df = merged_df.sort_values(by=\"Non-Null Count\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c3ea827",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns Sorted by Observations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Non-Null Count</th>\n",
       "      <th>Total Features</th>\n",
       "      <th>Coverage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name</td>\n",
       "      <td>172290</td>\n",
       "      <td>172290</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amenity</td>\n",
       "      <td>172290</td>\n",
       "      <td>172290</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>osm_way_id</td>\n",
       "      <td>63506</td>\n",
       "      <td>172290</td>\n",
       "      <td>36.859945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>source</td>\n",
       "      <td>59760</td>\n",
       "      <td>172290</td>\n",
       "      <td>34.685704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>addr:city</td>\n",
       "      <td>58358</td>\n",
       "      <td>172290</td>\n",
       "      <td>33.871960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>isced:level</td>\n",
       "      <td>53881</td>\n",
       "      <td>172290</td>\n",
       "      <td>31.273434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>operator:type</td>\n",
       "      <td>45279</td>\n",
       "      <td>172290</td>\n",
       "      <td>26.280690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>addr:district</td>\n",
       "      <td>44084</td>\n",
       "      <td>172290</td>\n",
       "      <td>25.587092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>source:date</td>\n",
       "      <td>25340</td>\n",
       "      <td>172290</td>\n",
       "      <td>14.707760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>name:en</td>\n",
       "      <td>21746</td>\n",
       "      <td>172290</td>\n",
       "      <td>12.621742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Column  Non-Null Count  Total Features  Coverage (%)\n",
       "1             name          172290          172290    100.000000\n",
       "3          amenity          172290          172290    100.000000\n",
       "135     osm_way_id           63506          172290     36.859945\n",
       "690         source           59760          172290     34.685704\n",
       "11       addr:city           58358          172290     33.871960\n",
       "14     isced:level           53881          172290     31.273434\n",
       "8    operator:type           45279          172290     26.280690\n",
       "70   addr:district           44084          172290     25.587092\n",
       "35     source:date           25340          172290     14.707760\n",
       "33         name:en           21746          172290     12.621742"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Printing sorted column coverage\n",
    "print(\"Columns Sorted by Observations:\")\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd65c0e8",
   "metadata": {},
   "source": [
    "### Saving the full dataset as GeoJSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78558d92",
   "metadata": {},
   "source": [
    "We won't use this dataset for the index calculation since it contains mainy unneeded columns. Saving it anyways in case it is of any use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "801ac78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the merged GeoJSON\n",
    "merged_data = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": merged_features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6619a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Saving the cleaned and merged GeoJSON\n",
    "with open(\"Africa/schools_merged_allcolumns.geojson\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(merged_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53e4a44",
   "metadata": {},
   "source": [
    "### Saving sub-selection of columns as GeoJSON for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e7e05d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = {\"name\", \"amenity\", \"isced:level\", \"grades\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f98ed00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing each feature to retain only selected columns\n",
    "for feature in merged_data[\"features\"]:\n",
    "    feature[\"properties\"] = {k: v for k, v in feature[\"properties\"].items() if k in columns_to_keep}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec35ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the filtered dataset as GeoJSON\n",
    "with open(\"Africa/schools_merged_finalcolumns.geojson\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(merged_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958ac369",
   "metadata": {},
   "source": [
    "# 2. Asia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bb4f58",
   "metadata": {},
   "source": [
    "### Turning polygon schools into points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc941532",
   "metadata": {},
   "source": [
    "Since some of the OSM schools are stored as polygons, we still need to turn them into points as well, so that they can seamlessly integrate with the point-based schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8fd05dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original CRS: EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "## Loading the multipolygon GeoJSON\n",
    "multipolygon_file = \"Asia/schools_full_polygons.geojson\"\n",
    "gdf_multi = gpd.read_file(multipolygon_file)\n",
    "\n",
    "## Checking the current CRS\n",
    "print(f\"Original CRS: {gdf_multi.crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9439d382",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting to projected CRS\n",
    "projected_gdf = gdf_multi.to_crs(\"EPSG:3857\")\n",
    "\n",
    "## Computing the centroids in projected coordinates\n",
    "projected_gdf[\"geometry\"] = projected_gdf[\"geometry\"].centroid\n",
    "\n",
    "## Converting back to geographic CRS for saving\n",
    "gdf_multi = projected_gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "## Saving as GeoJSON\n",
    "centroid_geojson = \"Asia/schools_centroids.geojson\"\n",
    "gdf_multi.to_file(centroid_geojson, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739c5c69",
   "metadata": {},
   "source": [
    "### Loading centroid and points file for cleaning and merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38340350",
   "metadata": {},
   "outputs": [],
   "source": [
    "## File paths\n",
    "nodes_file = \"Asia/schools_full_nodes.geojson\"\n",
    "centroids_file = \"Asia/schools_centroids.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9e8221cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading both GeoJSON files\n",
    "with open(centroids_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    centroids_data = json.load(f)\n",
    "\n",
    "with open(nodes_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    nodes_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38272d1",
   "metadata": {},
   "source": [
    "### Expanding the other_tags column in the centroids file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0449e4",
   "metadata": {},
   "source": [
    "The centroids file, which are the centerpoints of the schools captured as polygons in OSM, has a large number of tags collapsed into a single column. In the nodes file, which contains the schools captured as points in OSM, these tags all receive a seperate column. This step makes this also the case for the centroids file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d505e811",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying extract_other_tags function defined earlier when first running it for Africa\n",
    "\n",
    "for feature in centroids_data[\"features\"]:\n",
    "    feature[\"properties\"] = extract_other_tags(feature[\"properties\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ee3866",
   "metadata": {},
   "source": [
    "### Preparing centroid and node datasets for merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b16e8ce",
   "metadata": {},
   "source": [
    "The two datasets have slightly different structures. Here, we are cleaning and processing them so that they can be merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9c068d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing centroids: Removing None values using the clean_properties function defined when first running it for \n",
    "## Africa & ensuring \"name\" exists (if not, fallback to OSM ID)\n",
    "\n",
    "for feature in centroids_data[\"features\"]:\n",
    "    feature[\"properties\"] = clean_properties(feature[\"properties\"])\n",
    "    \n",
    "    if \"name\" not in feature[\"properties\"] or not feature[\"properties\"][\"name\"]:\n",
    "        feature[\"properties\"][\"name\"] = f\"Unnamed School (OSM ID: {feature['properties'].get('osm_id', 'Unknown')})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0de62003",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing nodes: Removing None values using the clean_properties function defined when first running it for\n",
    "## Africa & ensuring \"name\" exists (if not, fallback to OSM ID)\n",
    "\n",
    "for feature in nodes_data[\"features\"]:\n",
    "    feature[\"properties\"] = clean_properties(feature[\"properties\"])\n",
    "    \n",
    "    if \"name\" not in feature[\"properties\"] or not feature[\"properties\"][\"name\"]:\n",
    "        feature[\"properties\"][\"name\"] = f\"Unnamed School (OSM ID: {feature['properties'].get('osm_id', 'Unknown')})\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8c4c4f",
   "metadata": {},
   "source": [
    "### Merging the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b66a450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging\n",
    "merged_features = centroids_data[\"features\"] + nodes_data[\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a2ce2ee9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430214"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the number of schools included:\n",
    "len(merged_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1af2d9",
   "metadata": {},
   "source": [
    "### Checking columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c50f9b",
   "metadata": {},
   "source": [
    "There is a strong variety in detail for each school: sometimes a lot of detail is provided, other times only the name. Here we are checking what the most commonly provided details are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9b49b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Counting non-null values\n",
    "counts, total = count_non_nulls(merged_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4ea348af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting counts to dataframe for easy sorting\n",
    "merged_df = pd.DataFrame(list(counts.items()), columns=[\"Column\", \"Non-Null Count\"])\n",
    "merged_df[\"Total Features\"] = total\n",
    "merged_df[\"Coverage (%)\"] = (merged_df[\"Non-Null Count\"] / total) * 100\n",
    "merged_df = merged_df.sort_values(by=\"Non-Null Count\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2210e6d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Columns Sorted by Observations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Non-Null Count</th>\n",
       "      <th>Total Features</th>\n",
       "      <th>Coverage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name</td>\n",
       "      <td>430214</td>\n",
       "      <td>430214</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amenity</td>\n",
       "      <td>430214</td>\n",
       "      <td>430214</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>osm_way_id</td>\n",
       "      <td>292525</td>\n",
       "      <td>430214</td>\n",
       "      <td>67.995230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>operator:type</td>\n",
       "      <td>72222</td>\n",
       "      <td>430214</td>\n",
       "      <td>16.787459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>isced:level</td>\n",
       "      <td>70263</td>\n",
       "      <td>430214</td>\n",
       "      <td>16.332104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>operator</td>\n",
       "      <td>67019</td>\n",
       "      <td>430214</td>\n",
       "      <td>15.578061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>addr:city</td>\n",
       "      <td>57102</td>\n",
       "      <td>430214</td>\n",
       "      <td>13.272929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>name:en</td>\n",
       "      <td>54767</td>\n",
       "      <td>430214</td>\n",
       "      <td>12.730176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>addr:province</td>\n",
       "      <td>53815</td>\n",
       "      <td>430214</td>\n",
       "      <td>12.508891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>addr:street</td>\n",
       "      <td>49672</td>\n",
       "      <td>430214</td>\n",
       "      <td>11.545882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Column  Non-Null Count  Total Features  Coverage (%)\n",
       "1             name          430214          430214    100.000000\n",
       "3          amenity          430214          430214    100.000000\n",
       "608     osm_way_id          292525          430214     67.995230\n",
       "36   operator:type           72222          430214     16.787459\n",
       "63     isced:level           70263          430214     16.332104\n",
       "28        operator           67019          430214     15.578061\n",
       "8        addr:city           57102          430214     13.272929\n",
       "24         name:en           54767          430214     12.730176\n",
       "69   addr:province           53815          430214     12.508891\n",
       "6      addr:street           49672          430214     11.545882"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Showing top 10 columns in terms of coverage\n",
    "print(\"Top 10 Columns Sorted by Observations\")\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f85967",
   "metadata": {},
   "source": [
    "### Saving the full dataset as GeoJSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941d1319",
   "metadata": {},
   "source": [
    "We won't use this dataset for the index calculation since it contains mainy unneeded columns. Saving it anyways in case it is of any use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "95aa6fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the merged GeoJSON\n",
    "merged_data = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": merged_features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf92dd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Saving the cleaned and merged GeoJSON\n",
    "with open(\"Asia/schools_merged_allcolumns.geojson\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(merged_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaba84d0",
   "metadata": {},
   "source": [
    "### Saving sub-selection of columns as GeoJSON for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d2e4e484",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = {\"name\", \"amenity\", \"isced:level\", \"grades\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "be266d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing each feature to retain only selected columns\n",
    "for feature in merged_data[\"features\"]:\n",
    "    feature[\"properties\"] = {k: v for k, v in feature[\"properties\"].items() if k in columns_to_keep}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa7b9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the filtered dataset as GeoJSON\n",
    "with open(\"Asia/schools_merged_finalcolumns.geojson\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(merged_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a22c6bf",
   "metadata": {},
   "source": [
    "# 3. Europe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387425bd",
   "metadata": {},
   "source": [
    "### Turning polygon schools into points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a86f22d",
   "metadata": {},
   "source": [
    "Since some of the OSM schools are stored as polygons, we still need to turn them into points as well, so that they can seamlessly integrate with the point-based schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1740fb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original CRS: EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "## Loading the multipolygon GeoJSON\n",
    "multipolygon_file = \"Europe/schools_full_polygons.geojson\"\n",
    "gdf_multi = gpd.read_file(multipolygon_file)\n",
    "\n",
    "## Checking the current CRS\n",
    "print(f\"Original CRS: {gdf_multi.crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceff5a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting to projected CRS\n",
    "projected_gdf = gdf_multi.to_crs(\"EPSG:3857\")\n",
    "\n",
    "## Computing the centroids in projected coordinates\n",
    "projected_gdf[\"geometry\"] = projected_gdf[\"geometry\"].centroid\n",
    "\n",
    "## Converting back to geographic CRS for saving\n",
    "gdf_multi = projected_gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "## Saving as GeoJSON\n",
    "centroid_geojson = \"Europe/schools_centroids.geojson\"\n",
    "gdf_multi.to_file(centroid_geojson, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5329b146",
   "metadata": {},
   "source": [
    "### Loading centroid and points file for cleaning and merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "231894d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## File paths\n",
    "nodes_file = \"Europe/schools_full_nodes.geojson\"\n",
    "centroids_file = \"Europe/schools_centroids.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1aa02530",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading both GeoJSON files\n",
    "with open(centroids_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    centroids_data = json.load(f)\n",
    "\n",
    "with open(nodes_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    nodes_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22be6fd4",
   "metadata": {},
   "source": [
    "### Expanding the other_tags column in the centroids file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9f201f",
   "metadata": {},
   "source": [
    "The centroids file, which are the centerpoints of the schools captured as polygons in OSM, has a large number of tags collapsed into a single column. In the nodes file, which contains the schools captured as points in OSM, these tags all receive a seperate column. This step makes this also the case for the centroids file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a40a824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying extract_other_tags function defined earlier when first running it for Africa\n",
    "\n",
    "for feature in centroids_data[\"features\"]:\n",
    "    feature[\"properties\"] = extract_other_tags(feature[\"properties\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54ba91b",
   "metadata": {},
   "source": [
    "### Preparing centroid and node datasets for merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24b095b",
   "metadata": {},
   "source": [
    "The two datasets have slightly different structures. Here, we are cleaning and processing them so that they can be merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "990f628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing centroids: Removing None values using the clean_properties function defined when first running it for \n",
    "## Africa & ensuring \"name\" exists (if not, fallback to OSM ID)\n",
    "\n",
    "for feature in centroids_data[\"features\"]:\n",
    "    feature[\"properties\"] = clean_properties(feature[\"properties\"])\n",
    "\n",
    "    if \"name\" not in feature[\"properties\"] or not feature[\"properties\"][\"name\"]:\n",
    "        feature[\"properties\"][\"name\"] = f\"Unnamed School (OSM ID: {feature['properties'].get('osm_id', 'Unknown')})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "84027134",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing nodes: Removing None values using the clean_properties function defined when first running it for \n",
    "## Africa & ensuring \"name\" exists (if not, fallback to OSM ID)\n",
    "\n",
    "for feature in nodes_data[\"features\"]:\n",
    "    feature[\"properties\"] = clean_properties(feature[\"properties\"])\n",
    "\n",
    "    if \"name\" not in feature[\"properties\"] or not feature[\"properties\"][\"name\"]:\n",
    "        feature[\"properties\"][\"name\"] = f\"Unnamed School (OSM ID: {feature['properties'].get('osm_id', 'Unknown')})\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667d394a",
   "metadata": {},
   "source": [
    "### Merging the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "af747238",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging\n",
    "merged_features = centroids_data[\"features\"] + nodes_data[\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a813f21d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330206"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the number of schools included:\n",
    "len(merged_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bc4792",
   "metadata": {},
   "source": [
    "### Checking columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848682b7",
   "metadata": {},
   "source": [
    "There is a strong variety in detail for each school: sometimes a lot of detail is provided, other times only the name. Here we are checking what the most commonly provided details are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6a7c6342",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Counting non-null values\n",
    "counts, total = count_non_nulls(merged_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "805c8d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting counts to dataframe for easy sorting\n",
    "merged_df = pd.DataFrame(list(counts.items()), columns=[\"Column\", \"Non-Null Count\"])\n",
    "merged_df[\"Total Features\"] = total\n",
    "merged_df[\"Coverage (%)\"] = (merged_df[\"Non-Null Count\"] / total) * 100\n",
    "merged_df = merged_df.sort_values(by=\"Non-Null Count\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f1d89ace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Columns Sorted by Observations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Non-Null Count</th>\n",
       "      <th>Total Features</th>\n",
       "      <th>Coverage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amenity</td>\n",
       "      <td>330206</td>\n",
       "      <td>330206</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name</td>\n",
       "      <td>330206</td>\n",
       "      <td>330206</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>osm_way_id</td>\n",
       "      <td>253698</td>\n",
       "      <td>330206</td>\n",
       "      <td>76.830221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>addr:street</td>\n",
       "      <td>115333</td>\n",
       "      <td>330206</td>\n",
       "      <td>34.927591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>addr:postcode</td>\n",
       "      <td>109116</td>\n",
       "      <td>330206</td>\n",
       "      <td>33.044827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>addr:city</td>\n",
       "      <td>103737</td>\n",
       "      <td>330206</td>\n",
       "      <td>31.415843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>website</td>\n",
       "      <td>88575</td>\n",
       "      <td>330206</td>\n",
       "      <td>26.824164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>addr:housenumber</td>\n",
       "      <td>86403</td>\n",
       "      <td>330206</td>\n",
       "      <td>26.166393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>operator:type</td>\n",
       "      <td>76505</td>\n",
       "      <td>330206</td>\n",
       "      <td>23.168870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>phone</td>\n",
       "      <td>69436</td>\n",
       "      <td>330206</td>\n",
       "      <td>21.028085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Column  Non-Null Count  Total Features  Coverage (%)\n",
       "3             amenity          330206          330206    100.000000\n",
       "1                name          330206          330206    100.000000\n",
       "820        osm_way_id          253698          330206     76.830221\n",
       "7         addr:street          115333          330206     34.927591\n",
       "6       addr:postcode          109116          330206     33.044827\n",
       "5           addr:city          103737          330206     31.415843\n",
       "10            website           88575          330206     26.824164\n",
       "8    addr:housenumber           86403          330206     26.166393\n",
       "46      operator:type           76505          330206     23.168870\n",
       "21              phone           69436          330206     21.028085"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Showing top 10 columns in terms of coverage\n",
    "print(\"Top 10 Columns Sorted by Observations\")\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0a0dad",
   "metadata": {},
   "source": [
    "### Saving the full dataset as GeoJSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a4341e",
   "metadata": {},
   "source": [
    "We won't use this dataset for the index calculation since it contains mainy unneeded columns. Saving it anyways in case it is of any use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f78da8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the merged GeoJSON\n",
    "merged_data = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": merged_features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b74d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Saving the cleaned and merged GeoJSON\n",
    "with open(\"Europe/schools_merged_allcolumns.geojson\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(merged_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616beaef",
   "metadata": {},
   "source": [
    "### Saving sub-selection of columns as GeoJSON for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7e157848",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = {\"name\", \"amenity\", \"isced:level\", \"grades\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "24917af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing each feature to retain only selected columns\n",
    "for feature in merged_data[\"features\"]:\n",
    "    feature[\"properties\"] = {k: v for k, v in feature[\"properties\"].items() if k in columns_to_keep}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febaa82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the filtered dataset as GeoJSON\n",
    "with open(\"Europe/schools_merged_finalcolumns.geojson\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(merged_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bba2986",
   "metadata": {},
   "source": [
    "# 4. Australia & Oceania"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877c9dd1",
   "metadata": {},
   "source": [
    "### Turning polygon schools into points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd2006e",
   "metadata": {},
   "source": [
    "Since some of the OSM schools are stored as polygons, we still need to turn them into points as well, so that they can seamlessly integrate with the point-based schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f648dfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original CRS: EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "## Loading the multipolygon GeoJSON\n",
    "multipolygon_file = \"Australia-Oceania/schools_full_polygons.geojson\"\n",
    "gdf_multi = gpd.read_file(multipolygon_file)\n",
    "\n",
    "## Checking the current CRS\n",
    "print(f\"Original CRS: {gdf_multi.crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6a6446",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting to projected CRS\n",
    "projected_gdf = gdf_multi.to_crs(\"EPSG:3857\")\n",
    "\n",
    "## Computing the centroids in projected coordinates\n",
    "projected_gdf[\"geometry\"] = projected_gdf[\"geometry\"].centroid\n",
    "\n",
    "## Converting back to geographic CRS for saving\n",
    "gdf_multi = projected_gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "## Saving as GeoJSON\n",
    "centroid_geojson = \"Australia-Oceania/schools_centroids.geojson\"\n",
    "gdf_multi.to_file(centroid_geojson, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4ccb24",
   "metadata": {},
   "source": [
    "### Loading centroid and points file for cleaning and merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c3e49edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## File paths\n",
    "nodes_file = \"Australia-Oceania/schools_full_nodes.geojson\"\n",
    "centroids_file = \"Australia-Oceania/schools_centroids.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8bf8b008",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading both GeoJSON files\n",
    "with open(centroids_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    centroids_data = json.load(f)\n",
    "\n",
    "with open(nodes_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    nodes_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f09ec60",
   "metadata": {},
   "source": [
    "### Expanding the other_tags column in the centroids file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2b5be0",
   "metadata": {},
   "source": [
    "The centroids file, which are the centerpoints of the schools captured as polygons in OSM, has a large number of tags collapsed into a single column. In the nodes file, which contains the schools captured as points in OSM, these tags all receive a seperate column. This step makes this also the case for the centroids file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fc2df032",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying extract_other_tags function defined earlier when first running it for Africa\n",
    "\n",
    "for feature in centroids_data[\"features\"]:\n",
    "    feature[\"properties\"] = extract_other_tags(feature[\"properties\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc1d09e",
   "metadata": {},
   "source": [
    "### Preparing centroid and node datasets for merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749af522",
   "metadata": {},
   "source": [
    "The two datasets have slightly different structures. Here, we are cleaning and processing them so that they can be merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "72560706",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing centroids: Removing None values using the clean_properties function defined when first running it for \n",
    "## Africa & ensuring \"name\" exists (if not, fallback to OSM ID)\n",
    "\n",
    "for feature in centroids_data[\"features\"]:\n",
    "    feature[\"properties\"] = clean_properties(feature[\"properties\"])\n",
    "\n",
    "    if \"name\" not in feature[\"properties\"] or not feature[\"properties\"][\"name\"]:\n",
    "        feature[\"properties\"][\"name\"] = f\"Unnamed School (OSM ID: {feature['properties'].get('osm_id', 'Unknown')})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9268b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process nodes: Removing None values using the clean_properties function defined when first running it for \n",
    "## Africa & ensuring \"name\" exists (if not, fallback to OSM ID)\n",
    "\n",
    "for feature in nodes_data[\"features\"]:\n",
    "    feature[\"properties\"] = clean_properties(feature[\"properties\"])\n",
    "\n",
    "    if \"name\" not in feature[\"properties\"] or not feature[\"properties\"][\"name\"]:\n",
    "        feature[\"properties\"][\"name\"] = f\"Unnamed School (OSM ID: {feature['properties'].get('osm_id', 'Unknown')})\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb06e4f",
   "metadata": {},
   "source": [
    "### Merging the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c88141f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging\n",
    "merged_features = centroids_data[\"features\"] + nodes_data[\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e13664c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18430"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the number of schools included:\n",
    "len(merged_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadff859",
   "metadata": {},
   "source": [
    "### Checking columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e23ff",
   "metadata": {},
   "source": [
    "There is a strong variety in detail for each school: sometimes a lot of detail is provided, other times only the name. Here we are checking what the most commonly provided details are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "87eaa59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Counting non-null values\n",
    "counts, total = count_non_nulls(merged_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "35e2102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting counts to dataframe for easy sorting\n",
    "merged_df = pd.DataFrame(list(counts.items()), columns=[\"Column\", \"Non-Null Count\"])\n",
    "merged_df[\"Total Features\"] = total\n",
    "merged_df[\"Coverage (%)\"] = (merged_df[\"Non-Null Count\"] / total) * 100\n",
    "merged_df = merged_df.sort_values(by=\"Non-Null Count\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7137f803",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Columns Sorted by Observations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Non-Null Count</th>\n",
       "      <th>Total Features</th>\n",
       "      <th>Coverage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amenity</td>\n",
       "      <td>18430</td>\n",
       "      <td>18430</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name</td>\n",
       "      <td>18430</td>\n",
       "      <td>18430</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>osm_way_id</td>\n",
       "      <td>16451</td>\n",
       "      <td>18430</td>\n",
       "      <td>89.262073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>operator:type</td>\n",
       "      <td>7783</td>\n",
       "      <td>18430</td>\n",
       "      <td>42.230060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>addr:street</td>\n",
       "      <td>7678</td>\n",
       "      <td>18430</td>\n",
       "      <td>41.660336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>website</td>\n",
       "      <td>7670</td>\n",
       "      <td>18430</td>\n",
       "      <td>41.616929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>operator</td>\n",
       "      <td>7625</td>\n",
       "      <td>18430</td>\n",
       "      <td>41.372762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>grades</td>\n",
       "      <td>7608</td>\n",
       "      <td>18430</td>\n",
       "      <td>41.280521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>addr:housenumber</td>\n",
       "      <td>6439</td>\n",
       "      <td>18430</td>\n",
       "      <td>34.937602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>operator:wikidata</td>\n",
       "      <td>5439</td>\n",
       "      <td>18430</td>\n",
       "      <td>29.511666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Column  Non-Null Count  Total Features  Coverage (%)\n",
       "3             amenity           18430           18430    100.000000\n",
       "1                name           18430           18430    100.000000\n",
       "97         osm_way_id           16451           18430     89.262073\n",
       "13      operator:type            7783           18430     42.230060\n",
       "9         addr:street            7678           18430     41.660336\n",
       "16            website            7670           18430     41.616929\n",
       "12           operator            7625           18430     41.372762\n",
       "11             grades            7608           18430     41.280521\n",
       "20   addr:housenumber            6439           18430     34.937602\n",
       "14  operator:wikidata            5439           18430     29.511666"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Showing top 10 columns in terms of coverage\n",
    "print(\"Top 10 Columns Sorted by Observations\")\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c56b062",
   "metadata": {},
   "source": [
    "### Saving the full dataset as GeoJSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5dc030",
   "metadata": {},
   "source": [
    "We won't use this dataset for the index calculation since it contains mainy unneeded columns. Saving it anyways in case it is of any use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b0135da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the merged GeoJSON\n",
    "merged_data = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": merged_features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2269b97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Saving the cleaned and merged GeoJSON\n",
    "with open(\"Australia-Oceania/schools_merged_allcolumns.geojson\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(merged_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105581d8",
   "metadata": {},
   "source": [
    "### Saving sub-selection of columns as GeoJSON for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f9935472",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = {\"name\", \"amenity\", \"isced:level\", \"grades\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f3dbc1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing each feature to retain only selected columns\n",
    "for feature in merged_data[\"features\"]:\n",
    "    feature[\"properties\"] = {k: v for k, v in feature[\"properties\"].items() if k in columns_to_keep}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56048ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the filtered dataset as GeoJSON\n",
    "with open(\"Australia-Oceania/schools_merged_finalcolumns.geojson\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(merged_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fdd13e",
   "metadata": {},
   "source": [
    "# 5. South America"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c6d914",
   "metadata": {},
   "source": [
    "### Turning polygon schools into points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6843a7ac",
   "metadata": {},
   "source": [
    "Since some of the OSM schools are stored as polygons, we still need to turn them into points as well, so that they can seamlessly integrate with the point-based schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "73b0c11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original CRS: EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "## Loading the multipolygon GeoJSON\n",
    "multipolygon_file = \"South America/schools_full_polygons.geojson\"\n",
    "gdf_multi = gpd.read_file(multipolygon_file)\n",
    "\n",
    "## Checking the current CRS\n",
    "print(f\"Original CRS: {gdf_multi.crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281598bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting to projected CRS\n",
    "projected_gdf = gdf_multi.to_crs(\"EPSG:3857\")\n",
    "\n",
    "## Computing the centroids in projected coordinates\n",
    "projected_gdf[\"geometry\"] = projected_gdf[\"geometry\"].centroid\n",
    "\n",
    "## Converting back to geographic CRS for saving\n",
    "gdf_multi = projected_gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "## Saving as GeoJSON\n",
    "centroid_geojson = \"South America/schools_centroids.geojson\"\n",
    "gdf_multi.to_file(centroid_geojson, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130318bf",
   "metadata": {},
   "source": [
    "### Loading centroid and points file for cleaning and merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9aa970c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## File paths\n",
    "nodes_file = \"South America/schools_full_nodes.geojson\"\n",
    "centroids_file = \"South America/schools_centroids.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b38fcf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading both GeoJSON files\n",
    "with open(centroids_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    centroids_data = json.load(f)\n",
    "\n",
    "with open(nodes_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    nodes_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b285f1",
   "metadata": {},
   "source": [
    "### Expanding the other_tags column in the centroids file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f4906f",
   "metadata": {},
   "source": [
    "The centroids file, which are the centerpoints of the schools captured as polygons in OSM, has a large number of tags collapsed into a single column. In the nodes file, which contains the schools captured as points in OSM, these tags all receive a seperate column. This step makes this also the case for the centroids file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f40dba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying extract_other_tags function defined earlier when first running it for Africa\n",
    "\n",
    "for feature in centroids_data[\"features\"]:\n",
    "    feature[\"properties\"] = extract_other_tags(feature[\"properties\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229655f1",
   "metadata": {},
   "source": [
    "### Preparing centroid and node datasets for merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb58475",
   "metadata": {},
   "source": [
    "The two datasets have slightly different structures. Here, we are cleaning and processing them so that they can be merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "84322a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing centroids: Removing None values using the clean_properties function defined when first running it for \n",
    "## Africa & ensuring \"name\" exists (if not, fallback to OSM ID)\n",
    "\n",
    "for feature in centroids_data[\"features\"]:\n",
    "    feature[\"properties\"] = clean_properties(feature[\"properties\"])\n",
    "\n",
    "    if \"name\" not in feature[\"properties\"] or not feature[\"properties\"][\"name\"]:\n",
    "        feature[\"properties\"][\"name\"] = f\"Unnamed School (OSM ID: {feature['properties'].get('osm_id', 'Unknown')})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1bdd203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing nodes: Removing None values using the clean_properties function defined when first running it for \n",
    "## Africa & ensuring \"name\" exists (if not, fallback to OSM ID)\n",
    "\n",
    "for feature in nodes_data[\"features\"]:\n",
    "    feature[\"properties\"] = clean_properties(feature[\"properties\"])\n",
    "\n",
    "    if \"name\" not in feature[\"properties\"] or not feature[\"properties\"][\"name\"]:\n",
    "        feature[\"properties\"][\"name\"] = f\"Unnamed School (OSM ID: {feature['properties'].get('osm_id', 'Unknown')})\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fa8143",
   "metadata": {},
   "source": [
    "### Merging the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6132a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging\n",
    "merged_features = centroids_data[\"features\"] + nodes_data[\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5d527360",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207733"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the number of schools included:\n",
    "len(merged_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7efb75f",
   "metadata": {},
   "source": [
    "### Checking columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43f0efb",
   "metadata": {},
   "source": [
    "There is a strong variety in detail for each school: sometimes a lot of detail is provided, other times only the name. Here we are checking what the most commonly provided details are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3bfe015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Counting non-null values\n",
    "counts, total = count_non_nulls(merged_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a1376451",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting counts to dataframe for easy sorting\n",
    "merged_df = pd.DataFrame(list(counts.items()), columns=[\"Column\", \"Non-Null Count\"])\n",
    "merged_df[\"Total Features\"] = total\n",
    "merged_df[\"Coverage (%)\"] = (merged_df[\"Non-Null Count\"] / total) * 100\n",
    "merged_df = merged_df.sort_values(by=\"Non-Null Count\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4e4a8ddd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Columns Sorted by Observations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Non-Null Count</th>\n",
       "      <th>Total Features</th>\n",
       "      <th>Coverage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name</td>\n",
       "      <td>207733</td>\n",
       "      <td>207733</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amenity</td>\n",
       "      <td>207733</td>\n",
       "      <td>207733</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>addr:city</td>\n",
       "      <td>80496</td>\n",
       "      <td>207733</td>\n",
       "      <td>38.749741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>source</td>\n",
       "      <td>74536</td>\n",
       "      <td>207733</td>\n",
       "      <td>35.880674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>osm_way_id</td>\n",
       "      <td>71865</td>\n",
       "      <td>207733</td>\n",
       "      <td>34.594889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>isced:level</td>\n",
       "      <td>57995</td>\n",
       "      <td>207733</td>\n",
       "      <td>27.918049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>addr:street</td>\n",
       "      <td>55822</td>\n",
       "      <td>207733</td>\n",
       "      <td>26.871994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>operator:type</td>\n",
       "      <td>51034</td>\n",
       "      <td>207733</td>\n",
       "      <td>24.567113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ref</td>\n",
       "      <td>46225</td>\n",
       "      <td>207733</td>\n",
       "      <td>22.252122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>addr:full</td>\n",
       "      <td>45483</td>\n",
       "      <td>207733</td>\n",
       "      <td>21.894932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Column  Non-Null Count  Total Features  Coverage (%)\n",
       "1             name          207733          207733    100.000000\n",
       "3          amenity          207733          207733    100.000000\n",
       "7        addr:city           80496          207733     38.749741\n",
       "616         source           74536          207733     35.880674\n",
       "199     osm_way_id           71865          207733     34.594889\n",
       "44     isced:level           57995          207733     27.918049\n",
       "13     addr:street           55822          207733     26.871994\n",
       "32   operator:type           51034          207733     24.567113\n",
       "37             ref           46225          207733     22.252122\n",
       "49       addr:full           45483          207733     21.894932"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Showing top 10 columns in terms of coverage\n",
    "print(\"Top 10 Columns Sorted by Observations\")\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b840db",
   "metadata": {},
   "source": [
    "### Saving the full dataset as GeoJSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9a37f0",
   "metadata": {},
   "source": [
    "We won't use this dataset for the index calculation since it contains mainy unneeded columns. Saving it anyways in case it is of any use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c3f31519",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the merged GeoJSON\n",
    "merged_data = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": merged_features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b61c84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Saving the cleaned and merged GeoJSON\n",
    "with open(\"South America/schools_merged_allcolumns.geojson\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(merged_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6167ca",
   "metadata": {},
   "source": [
    "### Saving sub-selection of columns as GeoJSON for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f3ca9376",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = {\"name\", \"amenity\", \"isced:level\", \"grades\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9f1c2cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing each feature to retain only selected columns\n",
    "for feature in merged_data[\"features\"]:\n",
    "    feature[\"properties\"] = {k: v for k, v in feature[\"properties\"].items() if k in columns_to_keep}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a970c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the filtered dataset as GeoJSON\n",
    "with open(\"South America/schools_merged_finalcolumns.geojson\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(merged_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ad98d9",
   "metadata": {},
   "source": [
    "# 6. North America"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8ce8f3",
   "metadata": {},
   "source": [
    "### Turning polygon schools into points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6405d2",
   "metadata": {},
   "source": [
    "Since some of the OSM schools are stored as polygons, we still need to turn them into points as well, so that they can seamlessly integrate with the point-based schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "18db5817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original CRS: EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "## Loading the multipolygon GeoJSON\n",
    "multipolygon_file = \"North America/schools_full_polygons.geojson\"\n",
    "gdf_multi = gpd.read_file(multipolygon_file)\n",
    "\n",
    "## Checking the current CRS\n",
    "print(f\"Original CRS: {gdf_multi.crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aadb49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting to projected CRS\n",
    "projected_gdf = gdf_multi.to_crs(\"EPSG:3857\")\n",
    "\n",
    "## Computing the centroids in projected coordinates\n",
    "projected_gdf[\"geometry\"] = projected_gdf[\"geometry\"].centroid\n",
    "\n",
    "## Converting back to geographic CRS for saving\n",
    "gdf_multi = projected_gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "## Saving as GeoJSON\n",
    "centroid_geojson = \"North America/schools_centroids.geojson\"\n",
    "gdf_multi.to_file(centroid_geojson, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9172a4",
   "metadata": {},
   "source": [
    "### Loading centroid and points file for cleaning and merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "402c04ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## File paths\n",
    "nodes_file = \"North America/schools_full_nodes.geojson\"\n",
    "centroids_file = \"North America/schools_centroids.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4113b451",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading both GeoJSON files\n",
    "with open(centroids_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    centroids_data = json.load(f)\n",
    "\n",
    "with open(nodes_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    nodes_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6c8ca3",
   "metadata": {},
   "source": [
    "### Expanding the other_tags column in the centroids file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3714d72",
   "metadata": {},
   "source": [
    "The centroids file, which are the centerpoints of the schools captured as polygons in OSM, has a large number of tags collapsed into a single column. In the nodes file, which contains the schools captured as points in OSM, these tags all receive a seperate column. This step makes this also the case for the centroids file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e5236cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying extract_other_tags function defined earlier when first running it for Africa\n",
    "\n",
    "for feature in centroids_data[\"features\"]:\n",
    "    feature[\"properties\"] = extract_other_tags(feature[\"properties\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d6eb02",
   "metadata": {},
   "source": [
    "### Preparing centroid and node datasets for merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b125cda",
   "metadata": {},
   "source": [
    "The two datasets have slightly different structures. Here, we are cleaning and processing them so that they can be merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "83e07000",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing centroids: Removing None values using the clean_properties function defined when first running it for \n",
    "## Africa & ensuring \"name\" exists (if not, fallback to OSM ID)\n",
    "\n",
    "for feature in centroids_data[\"features\"]:\n",
    "    feature[\"properties\"] = clean_properties(feature[\"properties\"])\n",
    "\n",
    "    if \"name\" not in feature[\"properties\"] or not feature[\"properties\"][\"name\"]:\n",
    "        feature[\"properties\"][\"name\"] = f\"Unnamed School (OSM ID: {feature['properties'].get('osm_id', 'Unknown')})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9efb0ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing nodes: Removing None values using the clean_properties function defined when first running it for \n",
    "## Africa & ensuring \"name\" exists (if not, fallback to OSM ID)\n",
    "\n",
    "for feature in nodes_data[\"features\"]:\n",
    "    feature[\"properties\"] = clean_properties(feature[\"properties\"])\n",
    "\n",
    "    if \"name\" not in feature[\"properties\"] or not feature[\"properties\"][\"name\"]:\n",
    "        feature[\"properties\"][\"name\"] = f\"Unnamed School (OSM ID: {feature['properties'].get('osm_id', 'Unknown')})\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e2fe4c",
   "metadata": {},
   "source": [
    "### Merging the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "21eb032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging\n",
    "merged_features = centroids_data[\"features\"] + nodes_data[\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d06aebc5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197348"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the number of schools included:\n",
    "len(merged_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84133b56",
   "metadata": {},
   "source": [
    "### Checking columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6202c1ee",
   "metadata": {},
   "source": [
    "There is a strong variety in detail for each school: sometimes a lot of detail is provided, other times only the name. Here we are checking what the most commonly provided details are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7e250bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Counting non-null values\n",
    "counts, total = count_non_nulls(merged_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7cbd072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting counts to dataframe for easy sorting\n",
    "merged_df = pd.DataFrame(list(counts.items()), columns=[\"Column\", \"Non-Null Count\"])\n",
    "merged_df[\"Total Features\"] = total\n",
    "merged_df[\"Coverage (%)\"] = (merged_df[\"Non-Null Count\"] / total) * 100\n",
    "merged_df = merged_df.sort_values(by=\"Non-Null Count\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d8f06091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Columns Sorted by Observations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Non-Null Count</th>\n",
       "      <th>Total Features</th>\n",
       "      <th>Coverage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name</td>\n",
       "      <td>197348</td>\n",
       "      <td>197348</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amenity</td>\n",
       "      <td>197348</td>\n",
       "      <td>197348</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>osm_way_id</td>\n",
       "      <td>106244</td>\n",
       "      <td>197348</td>\n",
       "      <td>53.835864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gnis:feature_id</td>\n",
       "      <td>88429</td>\n",
       "      <td>197348</td>\n",
       "      <td>44.808663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>addr:street</td>\n",
       "      <td>63511</td>\n",
       "      <td>197348</td>\n",
       "      <td>32.182236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>addr:postcode</td>\n",
       "      <td>58513</td>\n",
       "      <td>197348</td>\n",
       "      <td>29.649654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>ele</td>\n",
       "      <td>57771</td>\n",
       "      <td>197348</td>\n",
       "      <td>29.273669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>addr:housenumber</td>\n",
       "      <td>47941</td>\n",
       "      <td>197348</td>\n",
       "      <td>24.292620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>operator</td>\n",
       "      <td>46787</td>\n",
       "      <td>197348</td>\n",
       "      <td>23.707866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>addr:city</td>\n",
       "      <td>43655</td>\n",
       "      <td>197348</td>\n",
       "      <td>22.120822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Column  Non-Null Count  Total Features  Coverage (%)\n",
       "1                name          197348          197348    100.000000\n",
       "3             amenity          197348          197348    100.000000\n",
       "297        osm_way_id          106244          197348     53.835864\n",
       "19    gnis:feature_id           88429          197348     44.808663\n",
       "9         addr:street           63511          197348     32.182236\n",
       "7       addr:postcode           58513          197348     29.649654\n",
       "954               ele           57771          197348     29.273669\n",
       "6    addr:housenumber           47941          197348     24.292620\n",
       "22           operator           46787          197348     23.707866\n",
       "5           addr:city           43655          197348     22.120822"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Showing top 10 columns in terms of coverage\n",
    "print(\"Top 10 Columns Sorted by Observations\")\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642d7e4b",
   "metadata": {},
   "source": [
    "### Saving the full dataset as GeoJSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deee16f2",
   "metadata": {},
   "source": [
    "We won't use this dataset for the index calculation since it contains mainy unneeded columns. Saving it anyways in case it is of any use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1242e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the merged GeoJSON\n",
    "merged_data = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": merged_features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527055a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Saving the cleaned and merged GeoJSON\n",
    "with open(\"North America/schools_merged_allcolumns.geojson\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(merged_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3be29dd",
   "metadata": {},
   "source": [
    "### Saving sub-selection of columns as GeoJSON for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ac380803",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = {\"name\", \"amenity\", \"isced:level\", \"grades\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5578d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing each feature to retain only selected columns\n",
    "for feature in merged_data[\"features\"]:\n",
    "    feature[\"properties\"] = {k: v for k, v in feature[\"properties\"].items() if k in columns_to_keep}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81a0cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the filtered dataset as GeoJSON\n",
    "with open(\"North America/schools_merged_finalcolumns.geojson\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(merged_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04df0a87",
   "metadata": {},
   "source": [
    "# 7. Central America"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a48bdcc",
   "metadata": {},
   "source": [
    "### Turning polygon schools into points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3704bccd",
   "metadata": {},
   "source": [
    "Since some of the OSM schools are stored as polygons, we still need to turn them into points as well, so that they can seamlessly integrate with the point-based schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1e9f0121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original CRS: EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "## Loading the multipolygon GeoJSON\n",
    "multipolygon_file = \"Central America/schools_full_polygons.geojson\"\n",
    "gdf_multi = gpd.read_file(multipolygon_file)\n",
    "\n",
    "## Checking the current CRS\n",
    "print(f\"Original CRS: {gdf_multi.crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbfa8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting to projected CRS\n",
    "projected_gdf = gdf_multi.to_crs(\"EPSG:3857\")\n",
    "\n",
    "## Computing the centroids in projected coordinates\n",
    "projected_gdf[\"geometry\"] = projected_gdf[\"geometry\"].centroid\n",
    "\n",
    "## Converting back to geographic CRS for saving\n",
    "gdf_multi = projected_gdf.to_crs(\"EPSG:4326\")\n",
    "\n",
    "## Saving as GeoJSON\n",
    "centroid_geojson = \"Central America/schools_centroids.geojson\"\n",
    "gdf_multi.to_file(centroid_geojson, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae063858",
   "metadata": {},
   "source": [
    "### Loading centroid and points file for cleaning and merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "181ebc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## File paths\n",
    "nodes_file = \"Central America/schools_full_nodes.geojson\"\n",
    "centroids_file = \"Central America/schools_centroids.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0f931c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading both GeoJSON files\n",
    "with open(centroids_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    centroids_data = json.load(f)\n",
    "\n",
    "with open(nodes_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    nodes_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7d9811",
   "metadata": {},
   "source": [
    "### Expanding the other_tags column in the centroids file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a16e81f",
   "metadata": {},
   "source": [
    "The centroids file, which are the centerpoints of the schools captured as polygons in OSM, has a large number of tags collapsed into a single column. In the nodes file, which contains the schools captured as points in OSM, these tags all receive a seperate column. This step makes this also the case for the centroids file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5a673624",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying extract_other_tags function defined earlier when first running it for Africa\n",
    "\n",
    "for feature in centroids_data[\"features\"]:\n",
    "    feature[\"properties\"] = extract_other_tags(feature[\"properties\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01305895",
   "metadata": {},
   "source": [
    "### Preparing centroid and node datasets for merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb4a640",
   "metadata": {},
   "source": [
    "The two datasets have slightly different structures. Here, we are cleaning and processing them so that they can be merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "be978568",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing centroids: Removing None values using the clean_properties function defined when first running it for \n",
    "## Africa & ensuring \"name\" exists (if not, fallback to OSM ID)\n",
    "\n",
    "for feature in centroids_data[\"features\"]:\n",
    "    feature[\"properties\"] = clean_properties(feature[\"properties\"])\n",
    "\n",
    "    if \"name\" not in feature[\"properties\"] or not feature[\"properties\"][\"name\"]:\n",
    "        feature[\"properties\"][\"name\"] = f\"Unnamed School (OSM ID: {feature['properties'].get('osm_id', 'Unknown')})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0489d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing nodes: Removing None values using the clean_properties function defined when first running it for \n",
    "## Africa & ensuring \"name\" exists (if not, fallback to OSM ID)\n",
    "\n",
    "for feature in nodes_data[\"features\"]:\n",
    "    feature[\"properties\"] = clean_properties(feature[\"properties\"])\n",
    "\n",
    "    if \"name\" not in feature[\"properties\"] or not feature[\"properties\"][\"name\"]:\n",
    "        feature[\"properties\"][\"name\"] = f\"Unnamed School (OSM ID: {feature['properties'].get('osm_id', 'Unknown')})\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e04e78c",
   "metadata": {},
   "source": [
    "### Merging the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6107b0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging\n",
    "merged_features = centroids_data[\"features\"] + nodes_data[\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "930c57db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25547"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the number of schools included:\n",
    "len(merged_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83480e9d",
   "metadata": {},
   "source": [
    "### Checking columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41649a1",
   "metadata": {},
   "source": [
    "There is a strong variety in detail for each school: sometimes a lot of detail is provided, other times only the name. Here we are checking what the most commonly provided details are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "05ed34f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Counting non-null values\n",
    "counts, total = count_non_nulls(merged_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e3f535e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting counts to dataframe for easy sorting\n",
    "merged_df = pd.DataFrame(list(counts.items()), columns=[\"Column\", \"Non-Null Count\"])\n",
    "merged_df[\"Total Features\"] = total\n",
    "merged_df[\"Coverage (%)\"] = (merged_df[\"Non-Null Count\"] / total) * 100\n",
    "merged_df = merged_df.sort_values(by=\"Non-Null Count\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9ff58326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Columns Sorted by Observations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Non-Null Count</th>\n",
       "      <th>Total Features</th>\n",
       "      <th>Coverage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amenity</td>\n",
       "      <td>25547</td>\n",
       "      <td>25547</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name</td>\n",
       "      <td>25547</td>\n",
       "      <td>25547</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>osm_way_id</td>\n",
       "      <td>14680</td>\n",
       "      <td>25547</td>\n",
       "      <td>57.462716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>addr:city</td>\n",
       "      <td>7793</td>\n",
       "      <td>25547</td>\n",
       "      <td>30.504560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>operator</td>\n",
       "      <td>6963</td>\n",
       "      <td>25547</td>\n",
       "      <td>27.255646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>addr:street</td>\n",
       "      <td>6047</td>\n",
       "      <td>25547</td>\n",
       "      <td>23.670098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>operator:type</td>\n",
       "      <td>5330</td>\n",
       "      <td>25547</td>\n",
       "      <td>20.863506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>source</td>\n",
       "      <td>4927</td>\n",
       "      <td>25547</td>\n",
       "      <td>19.286022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>grades</td>\n",
       "      <td>2373</td>\n",
       "      <td>25547</td>\n",
       "      <td>9.288762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>operational_status</td>\n",
       "      <td>2197</td>\n",
       "      <td>25547</td>\n",
       "      <td>8.599836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Column  Non-Null Count  Total Features  Coverage (%)\n",
       "3               amenity           25547           25547    100.000000\n",
       "1                  name           25547           25547    100.000000\n",
       "74           osm_way_id           14680           25547     57.462716\n",
       "9             addr:city            7793           25547     30.504560\n",
       "4              operator            6963           25547     27.255646\n",
       "10          addr:street            6047           25547     23.670098\n",
       "5         operator:type            5330           25547     20.863506\n",
       "407              source            4927           25547     19.286022\n",
       "11               grades            2373           25547      9.288762\n",
       "89   operational_status            2197           25547      8.599836"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Showing top 10 columns in terms of coverage\n",
    "print(\"Top 10 Columns Sorted by Observations\")\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff91acd8",
   "metadata": {},
   "source": [
    "### Saving the full dataset as GeoJSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262826fb",
   "metadata": {},
   "source": [
    "We won't use this dataset for the index calculation since it contains mainy unneeded columns. Saving it anyways in case it is of any use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e210be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the merged GeoJSON\n",
    "merged_data = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": merged_features\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88190c2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Saving the cleaned and merged GeoJSON\n",
    "with open(\"Central America/schools_merged_allcolumns.geojson\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(merged_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e828593",
   "metadata": {},
   "source": [
    "### Saving sub-selection of columns as GeoJSON for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "127b8f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = {\"name\", \"amenity\", \"isced:level\", \"grades\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4eaac440",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Processing each feature to retain only selected columns\n",
    "for feature in merged_data[\"features\"]:\n",
    "    feature[\"properties\"] = {k: v for k, v in feature[\"properties\"].items() if k in columns_to_keep}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938cb230",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the filtered dataset as GeoJSON\n",
    "with open(\"Central America/schools_merged_finalcolumns.geojson\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(merged_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8390a248",
   "metadata": {},
   "source": [
    "# 8. MERGING TO ONE GLOBAL FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a41c4c",
   "metadata": {},
   "source": [
    "### Loading the files created in the previous steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5ee155b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Africa = \"Africa/schools_merged_finalcolumns.geojson\"\n",
    "Asia = \"Asia/schools_merged_finalcolumns.geojson\"\n",
    "Europe = \"Europe/schools_merged_finalcolumns.geojson\"\n",
    "AustraliaOceania = \"Australia-Oceania/schools_merged_finalcolumns.geojson\"\n",
    "SouthAmerica = \"South America/schools_merged_finalcolumns.geojson\"\n",
    "NorthAmerica = \"North America/schools_merged_finalcolumns.geojson\"\n",
    "CentralAmerica = \"Central America/schools_merged_finalcolumns.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9b42541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Africa, \"r\", encoding=\"utf-8\") as f:\n",
    "    Africa_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "36a7e7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Asia, \"r\", encoding=\"utf-8\") as f:\n",
    "    Asia_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "613ad972",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Europe, \"r\", encoding=\"utf-8\") as f:\n",
    "    Europe_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b8147466",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(AustraliaOceania, \"r\", encoding=\"utf-8\") as f:\n",
    "    AustraliaOceania_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4ab6611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SouthAmerica, \"r\", encoding=\"utf-8\") as f:\n",
    "    SouthAmerica_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c62a1717",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(NorthAmerica, \"r\", encoding=\"utf-8\") as f:\n",
    "    NorthAmerica_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d233b81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CentralAmerica, \"r\", encoding=\"utf-8\") as f:\n",
    "    CentralAmerica_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2f18ad",
   "metadata": {},
   "source": [
    "### Merging the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "25aeea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging\n",
    "merged_continents = Africa_data[\"features\"] + Asia_data[\"features\"] + Europe_data[\"features\"] + AustraliaOceania_data[\"features\"] + SouthAmerica_data[\"features\"] + NorthAmerica_data[\"features\"]+ CentralAmerica_data[\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2e728db0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1381768"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking the number of schools included:\n",
    "len(merged_continents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efc313b",
   "metadata": {},
   "source": [
    "### Saving the global dataset as GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85271caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the merged GeoJSON\n",
    "merged_data = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": merged_continents\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3943a28b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Saving the cleaned and merged GeoJSON\n",
    "with open(\"00_GLOBAL FINAL/schools_global_unedited/schools_global_unedited.geojson\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(merged_data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aa0c8b",
   "metadata": {},
   "source": [
    "### Saving the global dataset as Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a1d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading GeoJSON\n",
    "gdf = gpd.read_file(\"00_GLOBAL FINAL/schools_global_unedited/schools_global_unedited.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da600cd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c1/ztjr47rx4_x9mxcz3smm67680000gn/T/ipykernel_79115/75029822.py:2: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  gdf.to_file(\"00_GLOBAL/schools_global_shp/schools_global.shp\")\n"
     ]
    }
   ],
   "source": [
    "## Saving as Shapefile\n",
    "gdf.to_file(\"00_GLOBAL FINAL/schools_global_unedited/schools_global_unedited.shp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
